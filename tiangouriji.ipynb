{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tiangouriji.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOGjn+rz4UD+Xh62aEoJ9Uh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JDHHH/RNN-generator/blob/master/tiangouriji.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lVd81U1smgZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "9e374225-273b-44d1-b351-87b65ec1e0a0"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/My Drive/tiangouriji\"\n",
        "os.listdir(path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['new.txt', 'new.gdoc', 'tiangouriji.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0s28zcvtoMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "file = open(\"/content/drive/My Drive/tiangouriji/new.txt\", \"r\",encoding='gbk') # 以只读模式读取文件\n",
        "lines = []\n",
        "for i in file:\n",
        "  if(i != '\\n'):\n",
        "    lines.append(i) #逐行将文本存入列表lines中  type(i):str\n",
        "file.close()\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2ezcy9vuz-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "22963881-f137-4f85-d062-01f57ff40672"
      },
      "source": [
        "for line in lines[:10]:\n",
        "    print(line)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "今天发工资了，我一个月工资1500，你猜我会给你多少？是不是觉得我会给你1200，自己留300吃饭？哈哈，我1500都给你，因为厂里包吃包住。\n",
            "\n",
            "你十分钟没有回我的消息在我孜孜不倦的骚扰下你终于舍得回我了 你说“憨憨”这其中一定有什么含义 可能说在夸我傻傻很可爱吧 我上百度搜了 也许你话没有说全 是不是你偷我这个憨憨的心所以变成敢敢呢 我感动哭了 原来是我自己感动了我自己 不知道你现在在干嘛呢 我很想你～\n",
            "\n",
            "我暗恋的人说眼睛疼，所以我买了瓶眼药水寄过去，但她却告诉我她有喜欢的人了，让我别再打扰。\n",
            "\n",
            "孩子生下来吧，我跟他姓\n",
            "\n",
            "你终于喊我双排了让我拿我胜率最高的英雄我一般都不玩的因为胜率太高了怕掉可是为了你我还是选了你好像很开心给我发了句fw，我懂了你是想夸夸我说我法王你真好我越来越喜欢你了\n",
            "\n",
            "你好像从来没有对我说过晚安，我在我们的聊天记录里搜索了关键字：“晚安”，你说过一次：我早晚安排人弄死你。\n",
            "\n",
            "你昨天晚上又没回我信息 我却看见你的游戏在线 在我再一次孜孜不倦的骚扰你的情况下 你终于跟我说了一句最长的话 “你他妈是不是有病” 我又陷入了沉思 这一定有什么含义 我想了很久你竟然提到了我的妈妈 原来你已经想得那么长远了 想和我结婚见我的父母 我太感动了真的 真的 那你现在在干嘛 我好想你 我妈妈说她也很喜欢你～\n",
            "\n",
            "早上骑了两个小时的自行车去买了你最爱吃的生煎包，拿到你面前的时候你说了句有病吗？都冷掉了。你一定是心疼我骑了那么久怕我冷的生病吧，今天也是爱你的一天。\n",
            "\n",
            "我暗恋的人说眼睛疼 所以我买了瓶眼药水寄过去，但他却告诉我他有喜欢的人了 让我别再打扰，距离遥远顺丰都要两天才能到，可他为什么只用了一秒就把眼药水滴进了我眼睛里\n",
            "\n",
            "我刚刚鼓起勇气给他发了句晚安，他回了一句，“再发tm拉黑你”我赶紧说，“求你别，我不说话了……”然后退了微信界面，壁纸是我ps的一张我俩的合照。\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK3GnoRxvW-I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c788f404-9291-49ff-e6c8-e327971cb06a"
      },
      "source": [
        "# 计算非重复字符的个数\n",
        "vocab = []\n",
        "for line in lines:\n",
        "    for bit in line:\n",
        "        if(bit not in vocab):\n",
        "            vocab.append(bit)\n",
        "print('有{}个非重复字符'.format(len(vocab)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "有1215个非重复字符\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QhxM9sLvXS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 给每个非重复字符编码\n",
        "import numpy as np\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "# print(char2idx)\n",
        "idx2char = np.array(vocab)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDMUQZJ7vXm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 将文本中的字与编码机型对应\n",
        "total = 0 \n",
        "text2idx = []\n",
        "for line in lines:\n",
        "    for c in line:\n",
        "        text2idx.append(char2idx[c])\n",
        "        total+=1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTqnppfyvr4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text2idx = np.array(text2idx)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD73Hi0_vXY5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e299ac00-aafb-421f-f1de-cb245d5c44ee"
      },
      "source": [
        "print('{}\\n{}'.format(repr(lines[:1]),text2idx[:73]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['今天发工资了，我一个月工资1500，你猜我会给你多少？是不是觉得我会给你1200，自己留300吃饭？哈哈，我1500都给你，因为厂里包吃包住。\\n']\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10  3  4 11 12 13 13  6 14 15  7 16 17 14\n",
            " 18 19 20 21 22 21 23 24  7 16 17 14 11 25 13 13  6 26 27 28 29 13 13 30\n",
            " 31 20 32 32  6  7 11 12 13 13 33 17 14  6 34 35 36 37 38 30 38 39 40 41\n",
            " 14]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0H9Xl-pvXGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 设定每个输入句子的长度\n",
        "seq_length = 100\n",
        "examples_per_epoch = total//seq_length"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtvhRDhrvWpV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "5d36e168-23dc-4e9e-f639-ab0e9cada2ec"
      },
      "source": [
        "# 创建训练样本\n",
        "import tensorflow as tf\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text2idx)\n",
        "\n",
        "for i in char_dataset.take(5):\n",
        "  print(idx2char[i.numpy()])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "今\n",
            "天\n",
            "发\n",
            "工\n",
            "资\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4e0o42Lv4oH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0165ce03-cf27-42d2-918d-fceeb7c0bf22"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(1):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'今天发工资了，我一个月工资1500，你猜我会给你多少？是不是觉得我会给你1200，自己留300吃饭？哈哈，我1500都给你，因为厂里包吃包住。\\n你十分钟没有回我的消息在我孜孜不倦的骚扰下你终于舍得回我了'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9XOgflKwYe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text,target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK4Oa_5txHsl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "00e842ba-0756-45fc-e8b1-65e7a90d15cd"
      },
      "source": [
        "for input_example,target_example in dataset.take(1):\n",
        "  print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data:  '今天发工资了，我一个月工资1500，你猜我会给你多少？是不是觉得我会给你1200，自己留300吃饭？哈哈，我1500都给你，因为厂里包吃包住。\\n你十分钟没有回我的消息在我孜孜不倦的骚扰下你终于舍得回我'\n",
            "Target data:  '天发工资了，我一个月工资1500，你猜我会给你多少？是不是觉得我会给你1200，自己留300吃饭？哈哈，我1500都给你，因为厂里包吃包住。\\n你十分钟没有回我的消息在我孜孜不倦的骚扰下你终于舍得回我了'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQCoMS5oxviK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "66efea90-a29b-4bb2-aefb-7bb5f13f3a6c"
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "  print(\"Step {:4d}\".format(i))\n",
        "  print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "  print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step    0\n",
            "  input: 0 ('今')\n",
            "  expected output: 1 ('天')\n",
            "Step    1\n",
            "  input: 1 ('天')\n",
            "  expected output: 2 ('发')\n",
            "Step    2\n",
            "  input: 2 ('发')\n",
            "  expected output: 3 ('工')\n",
            "Step    3\n",
            "  input: 3 ('工')\n",
            "  expected output: 4 ('资')\n",
            "Step    4\n",
            "  input: 4 ('资')\n",
            "  expected output: 5 ('了')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD3nSM-dyRDk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1b6f4d4-fbd6-4b2f-914b-f947c31318b1"
      },
      "source": [
        "# 批大小\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# 设定缓冲区大小，以重新排列数据集\n",
        "# （TF 数据被设计为可以处理可能是无限的序列，\n",
        "# 所以它不会试图在内存中重新排列整个序列。相反，\n",
        "# 它维持一个缓冲区，在缓冲区重新排列元素。） \n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdncKV0XyaIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 词集的长度\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# 嵌入的维度\n",
        "embedding_dim = 256\n",
        "\n",
        "# RNN 的单元数量\n",
        "rnn_units = 1024"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFXWVpMByckh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "              return_sequences=True,\n",
        "              stateful=True,\n",
        "              recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "              return_sequences=True,\n",
        "              stateful=True,\n",
        "              recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "              return_sequences=True,\n",
        "              stateful=True,\n",
        "              recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.GRU(rnn_units,\n",
        "              return_sequences=True,\n",
        "              stateful=True,\n",
        "              recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slZrhuqfymig",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "a3e46c1f-59fd-44c2-b917-7fb777c2bd6f"
      },
      "source": [
        "model = build_model(\n",
        "  vocab_size = len(vocab),\n",
        "  embedding_dim=embedding_dim,\n",
        "  rnn_units=rnn_units,\n",
        "  batch_size=BATCH_SIZE)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWl9iTVQypww",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "f2cb41a7-a0b3-4c20-a1d0-e167ff9099c0"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (64, None, 256)           311040    \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "gru_5 (GRU)                  (64, None, 1024)          6297600   \n",
            "_________________________________________________________________\n",
            "gru_6 (GRU)                  (64, None, 1024)          6297600   \n",
            "_________________________________________________________________\n",
            "gru_7 (GRU)                  (64, None, 1024)          6297600   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (64, None, 1215)          1245375   \n",
            "=================================================================\n",
            "Total params: 24,387,519\n",
            "Trainable params: 24,387,519\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjQS724nyvYW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21d75e74-493f-43a8-9daf-59311ca04923"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 1215) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKVfhFUNy19z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa8QpUory4ZM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "99a7d113-de5a-4c50-df01-c95da7f62a4e"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 817,  915,  986,  885,  214,  544,  489,  484,  747,  880, 1041,\n",
              "        416,  275,  693,  746, 1164,  861,  686,   67, 1044,  260,  962,\n",
              "        231,  897,  752,   61,  406,  584,  330, 1209,  624,  258,  286,\n",
              "        567,  520,   78,  149,  431,  961, 1007,  679,  420, 1046,   12,\n",
              "        607,  775,  741, 1102,  155, 1045,  146,  720, 1147,   50, 1081,\n",
              "          4,  981,  101, 1214, 1146,  521,  447, 1124,  822,  687,  134,\n",
              "        314,   35,  876, 1189,  816,  622, 1127,  276,  714,  181,  444,\n",
              "        760, 1125, 1167,  217,  235,  785,  157,  883, 1147,  205,  228,\n",
              "        320,  314,  267,  430,   50,  509,  758,  806,  695, 1166,  317,\n",
              "        728])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOeQwpDey8fR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "fe8819c9-8cd1-4b55-b322-7923dd886388"
      },
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: \n",
            " '屈我好想你\\n今天舔了一口狗，毛挺多，味道并不是很好，有一丝丝咸，毛有点硬，口感不是很好，应该是该洗澡了，然后被狗也舔了一口，他好像 吃了点特别的东西，味道挺怪，不过还是要感谢它，如果没有它，我今天又怎'\n",
            "\n",
            "Next Char Predictions: \n",
            " '梦派体探骑修午嘴佷圾昭牵厕杀贞式身握中吻s升要辆者说谈管！動继纸叫J老爱玩总旭页传内虹5覆名泪希好彩英快隐息默资罢知歡及实哥腩咸拳生应为速伞凉胳岁块腔弄处泡嘟迟时秒新开摆隐已遥嫌应化约息念吵世音极擒红'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBd-OUagza7x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "463d42f6-2855-476d-def4-f95907022505"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 1215)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       7.1024585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYGkGbayzh9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kOVkFVazlZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 检查点保存至的目录\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "\n",
        "# 检查点的文件名\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cyVOgagzoNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS=100"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK8l8iWtzqji",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0fe32729-e9a6-49bb-d201-e83562a6251d"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 2s 701ms/step - loss: 7.0194\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 2s 668ms/step - loss: 6.6590\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 2s 659ms/step - loss: 6.0045\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 2s 675ms/step - loss: 5.8449\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 2s 658ms/step - loss: 5.6482\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 2s 684ms/step - loss: 5.5753\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 4s 1s/step - loss: 5.5755\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 10s 3s/step - loss: 5.5546\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 4s 1s/step - loss: 5.5467\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 6s 2s/step - loss: 5.5454\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 7s 2s/step - loss: 5.5220\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 9s 3s/step - loss: 5.5275\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 4s 1s/step - loss: 5.5378\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 12s 4s/step - loss: 5.5204\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 2s 640ms/step - loss: 5.5267\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 11s 4s/step - loss: 5.5111\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 2s 664ms/step - loss: 5.5157\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 11s 4s/step - loss: 5.5018\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 2s 654ms/step - loss: 5.5264\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 10s 3s/step - loss: 5.4607\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 3s 1s/step - loss: 5.4396\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 11s 4s/step - loss: 5.3841\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 2s 800ms/step - loss: 5.3342\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 12s 4s/step - loss: 5.2383\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 2s 659ms/step - loss: 5.1699\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 6s 2s/step - loss: 5.0648\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 8s 3s/step - loss: 4.9750\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 6s 2s/step - loss: 4.8516\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 9s 3s/step - loss: 4.7422\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 6s 2s/step - loss: 4.5990\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 8s 3s/step - loss: 4.4527\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 3s 1s/step - loss: 4.3133\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 7s 2s/step - loss: 4.1654\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 9s 3s/step - loss: 4.0101\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 9s 3s/step - loss: 3.8632\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 2s 733ms/step - loss: 3.7239\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 12s 4s/step - loss: 3.4874\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 2s 654ms/step - loss: 3.3673\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 10s 3s/step - loss: 3.1901\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 2s 787ms/step - loss: 3.0961\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 9s 3s/step - loss: 2.9037\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 7s 2s/step - loss: 2.7016\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 4s 1s/step - loss: 2.5952\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 11s 4s/step - loss: 2.4317\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 2s 651ms/step - loss: 2.2803\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 9s 3s/step - loss: 2.1771\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 3s 1s/step - loss: 2.0410\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 6s 2s/step - loss: 1.9026\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 8s 3s/step - loss: 1.8446\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 9s 3s/step - loss: 1.6811\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 4s 1s/step - loss: 1.6295\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 10s 3s/step - loss: 1.5089\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 3s 904ms/step - loss: 1.4232\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 10s 3s/step - loss: 1.3262\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 3s 1s/step - loss: 1.2687\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 9s 3s/step - loss: 1.1665\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 4s 1s/step - loss: 1.0986\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 10s 3s/step - loss: 1.0365\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.9675\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.9051\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 3s 904ms/step - loss: 0.8558\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.7953\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.7487\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.6858\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.6549\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.6102\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.5775\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.5445\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.5270\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.4955\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.4573\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.4378\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.4228\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.4060\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.4010\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.3792\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.3660\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 2s 663ms/step - loss: 0.3514\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.3462\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 3s 871ms/step - loss: 0.3367\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 9s 3s/step - loss: 0.3137\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.3142\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.3040\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.2963\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.2872\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.2770\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.2794\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.2745\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.2606\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.2576\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.2508\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 4s 1s/step - loss: 0.2424\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.2457\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.2414\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.2312\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 10s 3s/step - loss: 0.2288\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 2s 759ms/step - loss: 0.2213\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.2249\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 8s 3s/step - loss: 0.2215\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.2107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g-w-qZM0Qqt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a96fbb56-be37-4e50-daa1-485c46cba863"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./training_checkpoints/ckpt_100'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfCx-ACA0ST6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9bLMTjS0UyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "b47a1ab3-e604-4816-8d59-dfa29a7d0faf"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (1, None, 256)            311040    \n",
            "_________________________________________________________________\n",
            "gru_8 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "gru_9 (GRU)                  (1, None, 1024)           6297600   \n",
            "_________________________________________________________________\n",
            "gru_10 (GRU)                 (1, None, 1024)           6297600   \n",
            "_________________________________________________________________\n",
            "gru_11 (GRU)                 (1, None, 1024)           6297600   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (1, None, 1215)           1245375   \n",
            "=================================================================\n",
            "Total params: 24,387,519\n",
            "Trainable params: 24,387,519\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHFMZVct0bjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # 评估步骤（用学习过的模型生成文本）\n",
        "\n",
        "  # 要生成的字符个数\n",
        "  num_generate = 100\n",
        "\n",
        "  # 将起始字符串转换为数字（向量化）\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # 空字符串用于存储结果\n",
        "  text_generated = []\n",
        "\n",
        "  # 低温度会生成更可预测的文本\n",
        "  # 较高温度会生成更令人惊讶的文本\n",
        "  # 可以通过试验以找到最好的设定\n",
        "  temperature = 1\n",
        "\n",
        "  # 这里批大小为 1\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # 删除批次的维度\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # 用分类分布预测模型返回的字符\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # 把预测字符和前面的隐藏状态一起传递给模型作为下一个输入\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhrWV5sF0jES",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "43c84bf8-85e0-4d03-bceb-4866b1e4f49b"
      },
      "source": [
        "print(generate_text(model, start_string=u\"今天\"))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "今天察才说我感是刺\n",
            "我爬妈幸下，我还是为你，就突在我无恋的，好能一0神时是你的我知道你是很是我哭“\n",
            "我的嘴注删了，这下我终于解放了！以前我总担心太多消息会打扰你，现在我终于不用顾忌，不管我怎总给你，给你连\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_dVIyJn0w_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}